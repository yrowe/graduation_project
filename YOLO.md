# YOLO

## 摘要
我们提出YOLO算法，一种全新的目标检测算法。先前的目标检测工作是重新规划分类器以执行检测。而我们将目标检测作为一个回归问题，从而在空间上分离包围盒和相关的类别概率。利用一个单一的神经网络在一次评测中直接从一幅完整的图像里预测包围盒和类概率。既然整个检测流程是一个单一的网络，那么它便可以以检测表现实行端对端的优化。

我们的统一架构极其之快。基础YOLO模型实时处理图片达到了45帧每秒。一个较小网络的版本，fast YOLO,在保持着相较其他实时检测算法双倍的mAP的同时，速度更是达到了惊人的155帧每秒。相较于其他的最新的目标检测系统，YOLO的定位失误较多，但能有效减少将背景错识别成目标的情况。最后，YOLO具有很好的泛化表达。当从自然图像泛化到其他领域时（如艺术品），YOLO则比其他检测方法（包括DPM和RCNN）更胜一筹。

##1.引言
人们瞥一眼图片，便立刻能知道图片里有哪些物体，它们在哪里以及它们之间的关系。人类的视觉系统是快速且准确的，使我们能够执行复杂的任务，如驾驶时没有意识的直觉。快速且准确的目标检测算法使得电脑在没有特定传感器的情况下行驶汽车，使辅助设备能够传递实时场景信息给用户，并解锁用以通用目的的，响应式机器人系统。
现有的检测系统复用分类器用以执行检测。为了检测物体，这些系统使用一个该物体的分类器，并在测试图像上的不同位置上以不同尺寸进行识别。像可变型部分模型（DPM）使用滑动窗口的方法，它的分类器在整幅图像的每个位置上均匀的划过，执行分类。

最近的方法，如R-CNN使用区域提议方法首先在图像中生成潜在的边界框，然后在这些提议框上运行分类器。在分类后，后处理工序用于细化边界框，消除重复检测，并基于场景中的其他物体，重新给包围盒评分。这些复杂的流程非常的慢，且因为每个独立的部分都需要单独的训练，使得其难以优化。

我们将目标检测重新设计为单一回归问题，从图像像素到边界框坐标和类概率。使用我们的系统，你只需要在图像上看一次（YOLO）就可以预测对象以及它们在哪。

YOLO很简单：参见图一。单个卷积网络同时预测包围盒的多个边界框和类概率。YOLO在完整的图片上训练并直接优化检测性能。这个统一的模型有几个相较于传统目标检测方法的优点。

首先，YOLO速度非常快。由于我们将检测规划成回归问题，所以我们不需要复杂的流程/管线。我们在测试中运行我们的神经网络在一个新的图像上来预测检测。我们的基础网络未经批处理的情况下在一块Titan X的GPU上速度有45帧每秒，而一个更快的版本更是达到了150帧每秒。这意味着我们可以以小于25毫秒的延迟实时处理流媒体视频。此外，YOLO有着高于其他实时系统的两倍的平均准确度。下面给出一个我们的系统作用于实时网络摄像头的项目，项目网页：
http://pjreddie.com/yolo/

其次，YOLO预测时参考了图像的全局信息。不同于划窗和基于区域提议的技术，YOLO在训练和测试期间会看见整幅图像，它隐式地编码关于类的上下文信息以及它们的外观。Fast R-CNN，一种顶尖的检测方法，由于无法看到更大的背景，会将部分背景错认成物体。而YOLO出现这种背景错误的数量相较Fast R-CNN少了一半。

第三，YOLO的泛化能力较强。当在自然图像上训练，在艺术品上测试时，YOLO相较DPM，R-CNN等顶级检测方法有大幅上涨。由于YOLO强大的泛化能力，当其适用于新领域或者接收到意外输入时，不太可能发生故障。

YOLO在准确度方面仍然落后最新的检测系统。尽管它可以快速识别图像中的物体，但它仍在努力精确定位某些物体，尤其是小物体。我们在我们的研究中会进一步考虑这些权衡。

我们所有的训练和测试的代码都是开源的。多个预训练模型同样也是提供下载的。

##2.统一检测

我们将物体检测的各个分散部分统一成一个单一的神经网络。我们的网络从整个图像中提取特征用以预测每个边界框。它也是同时预测图像中所有类的所有边界框。这意味着我们的网络考虑了整个图像的全局信息和图像中的所有物体。YOLO设计实现端到端训练和实时速度，同时保持较高的平均精度。

我们的系统将输入图像划分为S$\times$S网格。如果对象的中心落入网格单元内，则该网格单元负责检测该对象。

每个网格单元预测B个边界框和这些包围盒的置信度。这些预测的置信度反映了模型有多少确定一个包围盒包含了物体，以及它认为这个包围盒包含了物体的概率。最后我们定义置信度为$Pr(Object)*IOU^{truth}_{pred}$.如果该单元格内不存在物体，则置信度应当为0.否则，我们将置信度置为预测包围盒与真实值的交并比（IOU）。

每个边界框包含五个预测值：x, y, w, h以及置信度。（x, y)表示边界框中心相对于网格边界的坐标。预测的高度和宽度则是相对于整幅图像。而预测的置信度则表示的是预测框与任意真实边界框的IOU。

每个网格单元还预测了C个条件概率Pr(Classi|Object)。这些概率取决于包含物体的网格单元。我们只需要预测每个网格单元的一组类概率，而无需考虑包围盒个数B。

测试阶段，我们将条件类概率与该包围盒的置信度预测相乘，
$Pr(Class_i|Object)*Pr(Object)*IOU^{truth}_{pred}=Pr(Class_i)*IOU^{truth}_{pred}$
如上公式给予了我们对于每个包围盒的具体类的置信度。这些分数编码该类物体出现在包围盒里的概率以及预测框与真实物体适应度。

为了在PASCAL_VOC上评估YOLO，我们设定S=7，B=2。由于PACAL_VOC含有20类物体，所以我们设定C=20。综上，我们的最终预测为7*7*30的张量。

##2.1 网络设计
我们以卷积神经网络的形式实现该模型，并在PASCAL_VOC检测数据集上评测这个算法。初始卷积层从图像里提取特征，而全连接层输出概率与坐标。

