# Faster R-CNN
## 摘要：
　　最先进的目标识别网络决定于区域推荐算法去假设目标所在。先进的如SPPnet和Fast R-CNN降低了这些检测网络的运行时间，同时暴露出区域提出的计算是瓶颈。在本次工作中，我们介绍一种区域提出网络（RPN），这种网络与检测网络共享全图像卷积特征，因此，使区域提出接近无开销。RPN是一个全卷积网络，它同时预测物体边框和目标在每个位置的得分。RPN端到端的训练去生成高质量的推荐区域，并提供给Fast R-CNN去检测。在一个简单的转换优化后，RPN和Fast R-CNN可以共享卷积特征去训练。对于非常深的VGG-16模型，我们的检测系统在一块GPU上有着5FPS的帧率（包含了所有步骤），同时完成了最好的物体检测精度在PASCAL VOC 2007（73.2% mAP)和2012（70.4% mAP），每幅图片有约300个推荐区域。代码在https://github.com/ShaoqingRen/faster_rcnn.

---
## 介绍：
　　物体检测最新进展由区域推荐方法和基于区域的卷积神经网络（R-CNNs)的成功推动着。尽管最原始的基于区域的卷积神经网络需要非常大的计算资源，但这些开销随着推荐共享卷积而显著下降。最新的典型，Fast R-CNN，当忽视区域推荐的时间开销，使用非常深的网络也完成了接近实时的速率。现在，推荐部分是最先进的检测系统的计算瓶颈。

　　区域推荐方法主要依赖着简单特征和经济型的推理机制。一种最流行的方法：选择性搜索，基于低层次人工特征的贪心法合并超级像素。然而，相较于高效的检测网络，选择性搜索在CPU上完成一张图片耗时2秒，则慢了一个数量级。EdgeBoxes现今在推荐速度和准确度上有着最好的折中，每张图片0.2秒。然而，区域推荐步骤仍是整个目标检测算法中最耗时的部分。

　　或许有人注意到，快速基于区域的卷积神经网络得益于GPU，而区域推荐算法却是在CPU上完成搜索，所以造成了运行时间的不对等。理所当然的想到，用GPU去复现这部分以期实现加速。这或许是工程上一个有效的解决方案，但是这样的方法忽略了其后的检测网络也因此错失了共享计算的重要时机。

　　在本文中，我们展示一种算法的改变--利用深度网络计算建议框，这是一个优雅且有效的解决方案，同时建议框的计算几乎不会给检测网络带来计算开销。为此，我们引入了新颖的区域提议网络（RPN）他们与最新的物体检测网络共享卷积层。经过测试，通过共享卷积，计算建议框的边际成本是很小的（例如，每幅图像10ms)。

　　我们观察发现，基于区域的检测器例如Fast R-CNN,所用的卷积特征映射可同样被用于生成区域建议。在这些卷积特征之上，我们通过添加两个额外的卷积层来构建RPN：一层把每个卷积位置映射成一个短的特征向量（256维），第二层在每个卷积映射位置输出多个尺度和长宽比的k个区域的物体打分和回归边界（k=9是典型值）。

　　因此，我们的RPN是一种全卷积网络，他们可以专门为了生成检测建议的任务而进行端到端的训练。为了将RPN整合进Fast R-CNN，我们提出一个简单的训练规划，保持建议框固定，交替进行微调区域建议和微调物体检测。这个方案会迅速收敛，并产生一个两个任务共享卷积特征的统一网络。

　　我们在PASCAL VOC检测基准上评估我们的方法，在这个数据集上RPN和Fast R-CNN的检测精度超过了作为高基准的Fast R-CNN结合选择性搜索方法。同时，我们的方法几乎免除了测试阶段所有的选择性搜索的时间负担--提议建议框仅仅耗时10毫秒。使用非常深的模型，我们的检测方法仍然能在GPU上保持着5FPS的帧率。因此，就速度和准确度而言，这是一个实用的物体检测系统（73.2% mAP 于PASCAL VOC 2007，70.4% mAP 于PASCAL VOC 2012）。代码公开于 https://github.com/ShaoqingRen/faster_rcnn.


## 相关工作：
　　最近的几篇论文提出了使用深度网络定位确定的类或不确定的类的包围盒的方法。在OverFeat方法中，一个全连接层被训练用以预测假定单个对象的定位任务中的框坐标。该全连接层接下来转入卷积层用以预测多个确定的类。MutilBox的方法从最后一个全连接层同时预测多个（例如，800个）包围盒用以生成区域建议，R-CNN用的就是这个方法。他们的提议网络应用在单幅图像或者多个大图像的切割部分（例如，224 $\times$ 224)。稍后，我们会在后文中介绍我们方法时更加深入的讨论OverFeat和MultiBox。

　　共享卷积计算已经越来越受到人们的关注，从而获得高效而准确的视觉识别。OverFeat从图像金字塔中计算卷积特征用以分类，定位和检测。自适应大小池（SPP）为了有效的基于区域的物体检测和语义分割提出了共享卷积特征映射。Fast R-CNN可以训练共享卷积特征的端到端的检测器，并展现了令人信服的准确性和速度。

## 区域建议网络
区域建议网络将（任何大小的）图像作为输入并输出一组矩形对象提议，每个建议框都有一个目标得分。我们用全卷积网络对此过程进行建模，本节会详细描述。因为我们的最终目标是和Fast R-CNN物体检测网络共享计算，所以假定这两个网络共享一系列卷积层。在我们的实验中，我们研究了Zeiler和Fergus的模型（ZF），它具有5个可共享的卷积层，以及有13个可共享卷积层的Simonyan和Zisserman的模型（VGG）。

为了生成区域建议，我们在最后一个共享的卷积层输出的卷积特征映射上滑动一个小网络。该网络全连接到一个输入卷积特征映射的$n \times n$的时间窗口。每个滑窗被映射到一个较低维度的矢量上 （对于ZF是256维，对于VGG是512维）。这个向量被送进两个同级的全连接层--包围盒回归层(reg)和包围盒分类层（cls)。本文使用n=3，注意到输入图片的有效接受区域很大（ZF和VGG分别为171和228像素）。图1（左）展示了这个迷你网络在某个位置的情况。注意到，因为这个迷你网络是滑动窗口的形式，这个全连接层被所有空间位置共享。这种结构由一个$n \times n$的卷积层，后接两个同级的$1 \times 1$的卷积层（分别用以之后的reg和cls）实现。ReLUs层应用在$n \times n$的卷积层的输出。
