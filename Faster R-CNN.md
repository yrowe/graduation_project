# Faster R-CNN
## 摘要：
　　最先进的目标识别网络决定于区域推荐算法去假设目标所在。先进的如SPPnet和Fast R-CNN降低了这些检测网络的运行时间，同时暴露出区域提出的计算是瓶颈。在本次工作中，我们介绍一种区域提出网络（RPN），这种网络与检测网络共享全图像卷积特征，因此，使区域提出接近无开销。RPN是一个全卷积网络，它同时预测物体边框和目标在每个位置的得分。RPN端到端的训练去生成高质量的推荐区域，并提供给Fast R-CNN去检测。在一个简单的转换优化后，RPN和Fast R-CNN可以共享卷积特征去训练。对于非常深的VGG-16模型，我们的检测系统在一块GPU上有着5FPS的帧率（包含了所有步骤），同时完成了最好的物体检测精度在PASCAL VOC 2007（73.2% mAP)和2012（70.4% mAP），每幅图片有约300个推荐区域。代码在https://github.com/ShaoqingRen/faster_rcnn.

---
## 介绍：
　　物体检测最新进展由区域推荐方法和基于区域的卷积神经网络（R-CNNs)的成功推动着。尽管最原始的基于区域的卷积神经网络需要非常大的计算资源，但这些开销随着推荐共享卷积而显著下降。最新的典型，Fast R-CNN，当忽视区域推荐的时间开销，使用非常深的网络也完成了接近实时的速率。现在，推荐部分是最先进的检测系统的计算瓶颈。

　　区域推荐方法主要依赖着简单特征和经济型的推理机制。一种最流行的方法：选择性搜索，基于低层次人工特征的贪心法合并超级像素。然而，相较于高效的检测网络，选择性搜索在CPU上完成一张图片耗时2秒，则慢了一个数量级。EdgeBoxes现今在推荐速度和准确度上有着最好的折中，每张图片0.2秒。然而，区域推荐步骤仍是整个目标检测算法中最耗时的部分。

　　或许有人注意到，快速基于区域的卷积神经网络得益于GPU，而区域推荐算法却是在CPU上完成搜索，所以造成了运行时间的不对等。理所当然的想到，用GPU去复现这部分以期实现加速。这或许是工程上一个有效的解决方案，但是这样的方法忽略了其后的检测网络也因此错失了共享计算的重要时机。

　　在本文中，我们展示一种算法的改变--利用深度网络计算建议框，这是一个优雅且有效的解决方案，同时建议框的计算几乎不会给检测网络带来计算开销。为此，我们引入了新颖的区域提议网络（RPN）他们与最新的物体检测网络共享卷积层。经过测试，通过共享卷积，计算建议框的边际成本是很小的（例如，每幅图像10ms)。

　　我们观察发现，基于区域的检测器例如Fast R-CNN,所用的卷积特征映射可同样被用于生成区域建议。在这些卷积特征之上，我们通过添加两个额外的卷积层来构建RPN：一层把每个卷积位置映射成一个短的特征向量（256维），第二层在每个卷积映射位置输出多个尺度和长宽比的k个区域的物体打分和回归边界（k=9是典型值）。

　　因此，我们的RPN是一种全卷积网络，他们可以专门为了生成检测建议的任务而进行端到端的训练。为了将RPN整合进Fast R-CNN，我们提出一个简单的训练规划，保持建议框固定，交替进行微调区域建议和微调物体检测。这个方案会迅速收敛，并产生一个两个任务共享卷积特征的统一网络。

　　我们在PASCAL VOC检测基准上评估我们的方法，在这个数据集上RPN和Fast R-CNN的检测精度超过了作为高基准的Fast R-CNN结合选择性搜索方法。同时，我们的方法几乎免除了测试阶段所有的选择性搜索的时间负担--提议建议框仅仅耗时10毫秒。使用非常深的模型，我们的检测方法仍然能在GPU上保持着5FPS的帧率。因此，就速度和准确度而言，这是一个实用的物体检测系统（73.2% mAP 于PASCAL VOC 2007，70.4% mAP 于PASCAL VOC 2012）。代码公开于 https://github.com/ShaoqingRen/faster_rcnn.


## 相关工作：
　　最近的几篇论文提出了使用深度网络定位确定的类或不确定的类的包围盒的方法。在OverFeat方法中，一个全连接层被训练用以预测假定单个对象的定位任务中的框坐标。该全连接层接下来转入卷积层用以预测多个确定的类。MutilBox的方法从最后一个全连接层同时预测多个（例如，800个）包围盒用以生成区域建议，R-CNN用的就是这个方法。他们的提议网络应用在单幅图像或者多个大图像的切割部分（例如，224 $\times$ 224)。稍后，我们会在后文中介绍我们方法时更加深入的讨论OverFeat和MultiBox。

　　共享卷积计算已经越来越受到人们的关注，从而获得高效而准确的视觉识别。OverFeat从图像金字塔中计算卷积特征用以分类，定位和检测。自适应大小池（SPP）为了有效的基于区域的物体检测和语义分割提出了共享卷积特征映射。Fast R-CNN可以训练共享卷积特征的端到端的检测器，并展现了令人信服的准确性和速度。

## 区域建议网络
区域建议网络将（任何大小的）图像作为输入并输出一组矩形对象提议，每个建议框都有一个目标得分。我们用全卷积网络对此过程进行建模，本节会详细描述。因为我们的最终目标是和Fast R-CNN物体检测网络共享计算，所以假定这两个网络共享一系列卷积层。在我们的实验中，我们研究了Zeiler和Fergus的模型（ZF），它具有5个可共享的卷积层，以及有13个可共享卷积层的Simonyan和Zisserman的模型（VGG）。

为了生成区域建议，我们在最后一个共享的卷积层输出的卷积特征映射上滑动一个小网络。该网络全连接到一个输入卷积特征映射的$n \times n$的时间窗口。每个滑窗被映射到一个较低维度的矢量上 （对于ZF是256维，对于VGG是512维）。这个向量被送进两个同级的全连接层--包围盒回归层(reg)和包围盒分类层（cls)。本文使用n=3，注意到输入图片的有效接受区域很大（ZF和VGG分别为171和228像素）。图1（左）展示了这个迷你网络在某个位置的情况。注意到，因为这个迷你网络是滑动窗口的形式，这个全连接层被所有空间位置共享。这种结构由一个$n \times n$的卷积层，后接两个同级的$1 \times 1$的卷积层（分别用以之后的reg和cls）实现。ReLUs层应用在$n \times n$的卷积层的输出。

### 平移不变的锚
在每个滑动窗口的位置，我么同时预测$k$个区域提议框，所以reg层有$4k$个输出，即k个包围盒的坐标。cls层输出$2k$个分数估计每个提议框是目标或不是目标的概率。$k$个提议框被相应的$k$个被称为anchor的包围盒参数化。每个锚都位于滑动窗口的中心，并且与尺度和纵横比相关联。我们使用三个尺度和三个纵横比，这样在每个滑动位置就有9个锚。对于尺寸为$W \times H$（通常约为2400）的卷积特征映射，共有$WHk$个锚。我们方法的一个重要性质是平移不变性，对anchor和anchor相关的计算建议框函数都满足此性质。

作为比较，MultiBox的方法使用了k-means算法生成800个anchor，且不是平移不变的。如果平移图像中的物体，建议框也应相应平移，也应能用相同的函数预测任意位置的建议框。而且，因为MultiBox锚不是平移不变的，他需要$(4+1) \times    800$维的输出层，而我们的方法仅需$(4+2) \times 9$维的输出层。我们方法的建议框层参数少了一个数量级（MutilBox配合GoogLeNet要2700万参数，RPN配合VGG-16有240万参数），因此，在PASCAL VOC这样的小数据集上过拟合的风险较低。

### 学习区域建议的损失函数
为了训练RPN，我们为每个anchor分配一个二进制标签（表明是否为物体）。我们为以下两种anchor分配正值标签：(i)与实际的包围盒具有最大交并比的。（ii）与任意实际的包围盒有大于0.7的交并比的。 请注意，每个实际的包围盒可以分配给多个anchor以正值标签。若一个anchor和所有实际的包围盒交并比都小于0.3，则我们分配其负标签。非正非负的anchor对训练目标没有作用。

由如上定义，我们根据Fast R-CNN的多任务损失，最小化函数。函数定义为:
$L({p_i},{t_i})=\frac{1}{N_{cls}}\sum_iL_{cls}(p_i,p_i^*)+\lambda\frac{1}{N_{reg}}\sum_ip_i^*L_{reg}(t_i,t_i^*  )$
这里，$i$是一个迷你批次中anchor的索引，$P_i$是预测anchor i为物体的概率。anchor为正，则真实值标签为1，anchor为负，则真实值标签为0。$t_i$是表示预测包围盒的4个参数化坐标的矢量，$t_i^*$则表示与正值anchor对应的实际的包围盒。分类损失$L_{cls}$为两类(物体与非物体)的对数损失。对于回归损失，我们使用$L_{reg}(t_i,t_i^*)=R(t_i-t_i^*)$，其中R为[5]中定义的鲁棒的损失函数（smooth L1）。而$p_i^*L_{reg}$表示回归损失仅仅对于正值anchor激活（$p_i^*=1$），其余情况($p_i^*=0$)无效。cls和reg的层的输出分别由{$p_i$}和{$t_i$}组成。这两项由$N_{cls}$和$N_{reg}$和一个平衡参数$\lambda$正则化。

对于回归，我们采用如下参数化4个坐标的方法:
$t_x = (x-x_a)/w_a,  t_y = (y-y_a)/h_a, t_w = log(w/w_a), t_h = log(h/h_a)$
$t_x^* = (x^*-x_a)/w_a,  t_y^* = (y^*-y_a)/h_a, t_w^* = log(w^*/w_a), t_h^* = log(h^*/h_a)$
其中，x和y表示框中心坐标，w和h表示宽度和高度。变量x,x_a和x^*分别对应着预测包围盒，anchor包围盒以及实际的包围盒（$y$,$w$,$h$同理）。此处可认为是从anchor包围盒到相近的实际包围盒的包围盒回归。

不过，我们的方法以不同于之前基于特征映射的方法实现了包围盒回归。此前的方法中，包围盒回归应用在任意大小的区域池化到特征上，且所有大小区域共享回归权值。在我们的公式里，用以回归的特征在特征映射上具有相同的空间大小（$n \times n$)。考虑不同大小，需要学习一系列k个包围盒的回归量。每个回归量对应一个尺寸和长宽比，且这k个回归量不共享权值。因此，即使特征具有固定的大小/比例，仍然可以预测各个大小的包围盒。

### 优化
自然地，RPN由全卷积网络实现，通过反向传播和随机梯度下降（SGD)端到端地训练。我们遵循"imagecentric"的采样策略来训练这个网络。每个mini-batch由包含许多正负anchor的单幅图像组成。可以根据损失函数来优化所有anchor，但是这将偏向负样本，因为他们占据了主导地位。相反，我们通过随机采样每幅图像中的256个anchor去计算mini-batch的损失函数，其中采样正负anchor比为1:1。如果一幅图像中正样本个数少于128,我们用负样本填充mini-batch。

我们通过一个均值为0，标准差为0.01的高斯分布随机初始化所有新层。而依照惯用做法，所有其他层（即共享卷积层）是由在ImageNet分类数据集预训练过的模型初始化的。我们调整ZF网络的所有层和conv3_1，为给VGG网络作准备以节省内存。我们在PASCAL数据集中的6万个mini-batch上使用了0.001的学习率，接下来的2万个mini-batch上使用0.0001的学习率。动量是0.9，权重衰减0.0005。我们使用caffe框架实现代码。

### 区域建议和物体检测共享卷积特征
到目前为止，我们描述了如何训练用于生成区域建议的网络。而未考虑基于区域的物体检测CNN利用这些提议框。对于检测网络，我们采用Fast R-CNN,现在介绍一种算法，在RPN和Fast R-CNN间共享卷积层。

独立训练的RPN和Fast R-CNN以不同的方式调整自己的卷积层。因此，我们需要开发一种允许在两个网络之间共享卷积层的技术，而不是学习两个分离的网络。请注意，这并非是简单地定义一个包含RPN和Fast R-CNN的网络，然后通过反向传播优化那么容易。这是因为Fast R-CNN的训练依赖于固定的目标提议，且尚未由先验知识说明，在改变提议机制的情况下训练Fast R-CNN时能达到收敛。虽然在未来这种联合优化是个很有趣的问题，我们开发了一个使用的4步训练算法，通过交替优化学习共享特征。

第一步，我们如上所述训练RPN。该网络使用ImageNet的预训练模型初始化，并针对区域提议任务进行端到端微调。第二步，我们通过Fast R-CNN使用第一步RPN生成的提议来训练单独的检测网络。同样地，我们用ImageNet预训练模型来初始化这个网络。到这里，这两个网络还没有共享卷积层。第三步，我们用检测网络初始化RPN的训练，但我们固定共享的卷积层并且只微调RPN独有的层。现在，这两个网络共享卷积层了。最后，保持共享的卷积层固定，我们微调Fast R-CNN的全连接层。至此，这两网络共享相同的卷积层并形成了一个统一的网络。

### 实现细节
我们在单规模图像上训练和测试区域提议和物体检测网络。我们重新缩放图片，使其短边s = 600像素。多尺度特征提取或许会提高准确度但是无法做到速度和精度的折中。我们也注意到，对于ZF和VGG网络，对缩放后的图像在最后的卷积层上的总步长是16像素，因此在典型的PASCAL图像（500 x 375）上约为10个像素。即使如此大的步长提供了很好的结果，准确度仍可能继续提高通过缩短步长。



